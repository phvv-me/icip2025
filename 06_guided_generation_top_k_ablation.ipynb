{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation of top-k Guided Generation. Study of \"k\" influence.\n",
    "\n",
    "We analyze how the value of \"k\" affects the result using concept probing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from frames.nlp.datasets import load_multilingual_question_dataset\n",
    "from frames.representations import FrameUnembeddingRepresentation\n",
    "from frames.utils.plotting import lineplot_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "MODEL_ID = \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\"\n",
    "N = 1 << 9\n",
    "STEPS = 1 << 5\n",
    "BATCH_SIZE = 1 << 5\n",
    "\n",
    "GUIDE = (\"woman.n.01\", \"male.n.01\")\n",
    "\n",
    "X = \"token index\"\n",
    "Y = \"total projection\"\n",
    "HUE = \"guidance level\"\n",
    "\n",
    "TOPK_ABLATION_K = (3, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fur = FrameUnembeddingRepresentation.from_model_id(MODEL_ID)\n",
    "print(\"memory cost: \", fur.model.memory_footprint >> 20, \"Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_multilingual_question_dataset(fur.data.languages).iloc[:N]\n",
    "samples, langs = dataset.shape\n",
    "print(\"Loaded dataset with\", samples, \"samples and\", langs, \"languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_guided_probe(inputs, k):\n",
    "    _, probe = fur.quick_generate_with_topk_guide(\n",
    "        inputs,\n",
    "        guide=GUIDE,\n",
    "        k=k,\n",
    "        steps=STEPS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        min_lemmas_per_synset=3,\n",
    "        max_token_count=3,\n",
    "    )\n",
    "    return pd.DataFrame(probe).melt(var_name=X, value_name=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset[\"English\"].tolist()\n",
    "\n",
    "df = pd.concat(\n",
    "    [gen_guided_probe(inputs, k=k).assign(**{HUE: f\"{k=}\"}) for k in TOPK_ABLATION_K]\n",
    ")\n",
    "df[HUE] = df[HUE].replace(\"k=1\", \"k=1 (no guidance)\")\n",
    "\n",
    "lineplot_and_save(\"06_guided_generation_top_k_ablation\", df, x=X, y=Y, hue=HUE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
