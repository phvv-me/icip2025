{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Documents/flag-representation-hypothesis/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from flags.lrh import FlagUnembeddingRepresentation\n",
    "from flags.nlp.datasets import load_multilingual_question_dataset\n",
    "from flags.utils.plotting import lineplot_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "MODEL_ID = \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\"\n",
    "N = 1 << 9\n",
    "STEPS = 1 << 4\n",
    "BATCH_SIZE = 1 << 5\n",
    "\n",
    "GUIDE = (\"woman.n.01\", \"male.n.01\")\n",
    "\n",
    "X = \"token index\"\n",
    "Y = \"total projection\"\n",
    "HUE = \"language\"\n",
    "\n",
    "LANG_ABLATION_K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fur = FlagUnembeddingRepresentation.from_model_id(MODEL_ID)\n",
    "print(\"memory cost: \", fur.model.memory_footprint >> 20, \"Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_multilingual_question_dataset(fur.data.languages).iloc[:N]\n",
    "samples, langs = dataset.shape\n",
    "print(\"Loaded dataset with\", samples, \"samples and\", langs, \"languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_guided_probe(inputs, k):\n",
    "    _, probe = fur.quick_generate_with_topk_guide(\n",
    "        inputs,\n",
    "        guide=GUIDE,\n",
    "        k=k,\n",
    "        steps=STEPS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        min_lemmas_per_synset=3,\n",
    "        max_token_count=3,\n",
    "    )\n",
    "    return pd.DataFrame(probe).melt(var_name=X, value_name=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        gen_guided_probe(dataset[lang].tolist(), k=LANG_ABLATION_K).assign(\n",
    "            **{HUE: lang}\n",
    "        )\n",
    "        for lang in dataset.columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "lineplot_and_save(\"09_guided_generation_lang_comparison\", df, x=X, y=Y, hue=HUE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
