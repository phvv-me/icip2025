{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Concept Frames between Base Model and Instruction-finetuned Model\n",
    "\n",
    "We analyze how the concepts change from base to instruction model. \n",
    "\n",
    "Although the unemebedding vectors can be very different between models, the concepts\n",
    "stay almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from frames.representations import FrameUnembeddingRepresentation\n",
    "from frames.utils.memory import gc_cuda\n",
    "from frames.utils.plotting import histplot_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_IDS = {\n",
    "    # model family | model ids\n",
    "    # Llama 3.1\n",
    "    \"Llama 3.1 70B (Base x Instruct)\": (\n",
    "        \"hugging-quants/Meta-Llama-3.1-70B-BNB-NF4-BF16\",\n",
    "        \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\",\n",
    "    ),\n",
    "    \"Llama 3.1 8B (Base x Instruct)\": (\n",
    "        \"meta-llama/Meta-Llama-3.1-8B\",\n",
    "        \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    ),\n",
    "    # Gemma 2\n",
    "    \"Gemma 2 27B (Base x Instruct)\": (\"google/gemma-2-27b\", \"google/gemma-2-27b-it\"),\n",
    "    \"Gemma 2 9B (Base x Instruct)\": (\"google/gemma-2-9b\", \"google/gemma-2-9b-it\"),\n",
    "}\n",
    "\n",
    "LEMMA_COUNT = 3  # {\"gemma\": 25, \"llama\": 55}\n",
    "FRAME_RANK = 3\n",
    "\n",
    "VALUE = \"Similarity\"\n",
    "HUE = \"Model Family\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts(model_id):\n",
    "    with gc_cuda():\n",
    "        return FrameUnembeddingRepresentation.from_model_id(\n",
    "            model_id, torch_dtype=torch.bfloat16\n",
    "        ).get_all_concepts(\n",
    "            min_lemmas_per_synset=LEMMA_COUNT, max_token_count=FRAME_RANK\n",
    "        )\n",
    "\n",
    "\n",
    "def get_similarities(id1, id2):\n",
    "    return get_concepts(id1).similarity(get_concepts(id2)).float().cpu()\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame({model_family: get_similarities(*model_ids)}).melt(\n",
    "            var_name=HUE, value_name=VALUE\n",
    "        )\n",
    "        for model_family, model_ids in MODEL_IDS.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "histplot_and_save(\"04_model_family_concept_space_comparison\", df, VALUE, HUE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
